{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V-LmX-H6aoK"
      },
      "source": [
        "# Importing the dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBqbGsCV4V9l",
        "outputId": "63a22011-198c-4c5c-e4ea-0f7178a4f053"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (2.12.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from emoji) (4.11.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pt_k83Cp6PQb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import string\n",
        "import textblob\n",
        "import nltk\n",
        "import emoji\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBTEm4ItSx6r",
        "outputId": "7777e3b2-e2a3-4c8e-97e1-c38128c153b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "nltk.download(\"stopwords\")\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o4PVuhu6vEM"
      },
      "source": [
        "# Loading the Data\n",
        "Here, we will load the data of IMDB dataset that has 50K movie reviews with their sentiment as either positive or negative.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "YKHbS6X46yDC",
        "outputId": "95a3f946-bdc3-41ea-a17d-c5bb9ea4d113"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "5  Probably my all-time favorite movie, a story o...  positive\n",
              "6  I sure would like to see a resurrection of a u...  positive\n",
              "7  This show was an amazing, fresh & innovative i...  negative\n",
              "8  Encouraged by the positive comments about this...  negative\n",
              "9  If you like original gut wrenching laughter yo...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c121fee1-0283-481e-a5c3-817479fbffd7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Probably my all-time favorite movie, a story o...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I sure would like to see a resurrection of a u...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Encouraged by the positive comments about this...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>If you like original gut wrenching laughter yo...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c121fee1-0283-481e-a5c3-817479fbffd7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c121fee1-0283-481e-a5c3-817479fbffd7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c121fee1-0283-481e-a5c3-817479fbffd7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fb8f8dc8-8fed-4ca8-904c-c14f9d8defda\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fb8f8dc8-8fed-4ca8-904c-c14f9d8defda')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fb8f8dc8-8fed-4ca8-904c-c14f9d8defda button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49582,\n        \"samples\": [\n          \"\\\"Soul Plane\\\" is a horrible attempt at comedy that only should appeal people with thick skulls, bloodshot eyes and furry pawns. <br /><br />The plot is not only incoherent but also non-existent, acting is mostly sub sub-par with a gang of highly moronic and dreadful characters thrown in for bad measure, jokes are often spotted miles ahead and almost never even a bit amusing. This movie lacks any structure and is full of racial stereotypes that must have seemed old even in the fifties, the only thing it really has going for it is some pretty ladies, but really, if you want that you can rent something from the \\\"Adult\\\" section. OK?<br /><br />I can hardly see anything here to recommend since you'll probably have a lot a better and productive time chasing rats with a sledgehammer or inventing waterproof teabags or whatever.<br /><br />2/10\",\n          \"Guest from the Future tells a fascinating story of time travel, friendship, battle of good and evil -- all with a small budget, child actors, and few special effects. Something for Spielberg and Lucas to learn from. ;) A sixth-grader Kolya \\\"Nick\\\" Gerasimov finds a time machine in the basement of a decrepit building and travels 100 years into the future. He discovers a near-perfect, utopian society where robots play guitars and write poetry, everyone is kind to each other and people enjoy everything technology has to offer. Alice is the daughter of a prominent scientist who invented a device called Mielophone that allows to read minds of humans and animals. The device can be put to both good and bad use, depending on whose hands it falls into. When two evil space pirates from Saturn who want to rule the universe attempt to steal Mielophone, it falls into the hands of 20th century school boy Nick. With the pirates hot on his tracks, he travels back to his time, followed by the pirates, and Alice. Chaos, confusion and funny situations follow as the luckless pirates try to blend in with the earthlings. Alice enrolls in the same school Nick goes to and demonstrates superhuman abilities in PE class. The catch is, Alice doesn't know what Nick looks like, while the pirates do. Also, the pirates are able to change their appearance and turn literally into anyone. (Hmm, I wonder if this is where James Cameron got the idea for Terminator...) Who gets to Nick -- and Mielophone -- first? Excellent plot, non-stop adventures, and great soundtrack. I wish Hollywood made kid movies like this one...\",\n          \"\\\"National Treasure\\\" (2004) is a thoroughly misguided hodge-podge of plot entanglements that borrow from nearly every cloak and dagger government conspiracy clich\\u00e9 that has ever been written. The film stars Nicholas Cage as Benjamin Franklin Gates (how precious is that, I ask you?); a seemingly normal fellow who, for no other reason than being of a lineage of like-minded misguided fortune hunters, decides to steal a 'national treasure' that has been hidden by the United States founding fathers. After a bit of subtext and background that plays laughably (unintentionally) like Indiana Jones meets The Patriot, the film degenerates into one misguided whimsy after another \\u0096 attempting to create a 'Stanley Goodspeed' regurgitation of Nicholas Cage and launch the whole convoluted mess forward with a series of high octane, but disconnected misadventures.<br /><br />The relevancy and logic to having George Washington and his motley crew of patriots burying a king's ransom someplace on native soil, and then, going through the meticulous plan of leaving clues scattered throughout U.S. currency art work, is something that director Jon Turteltaub never quite gets around to explaining. Couldn't Washington found better usage for such wealth during the start up of the country? Hence, we are left with a mystery built on top of an enigma that is already on shaky ground by the time Ben appoints himself the new custodian of this untold wealth. Ben's intentions are noble \\u0096 if confusing. He's set on protecting the treasure. For who and when?\\u0085your guess is as good as mine.<br /><br />But there are a few problems with Ben's crusade. First up, his friend, Ian Holmes (Sean Bean) decides that he can't wait for Ben to make up his mind about stealing the Declaration of Independence from the National Archives (oh, yeah \\u0096 brilliant idea!). Presumably, the back of that famous document holds the secret answer to the ultimate fortune. So Ian tries to kill Ben. The assassination attempt is, of course, unsuccessful, if overly melodramatic. It also affords Ben the opportunity to pick up, and pick on, the very sultry curator of the archives, Abigail Chase (Diane Kruger). She thinks Ben is clearly a nut \\u0096 at least at the beginning. But true to action/romance form, Abby's resolve melts quicker than you can say, \\\"is that the Hope Diamond?\\\" The film moves into full X-File-ish mode, as the FBI, mistakenly believing that Ben is behind the theft, retaliate in various benign ways that lead to a multi-layering of action sequences reminiscent of Mission Impossible meets The Fugitive. Honestly, don't those guys ever get 'intelligence' information that is correct? In the final analysis, \\\"National Treasure\\\" isn't great film making, so much as it's a patchwork rehash of tired old bits from other movies, woven together from scraps, the likes of which would make IL' Betsy Ross blush.<br /><br />The Buena Vista DVD delivers a far more generous treatment than this film is deserving of. The anamorphic widescreen picture exhibits a very smooth and finely detailed image with very rich colors, natural flesh tones, solid blacks and clean whites. The stylized image is also free of blemishes and digital enhancements. The audio is 5.1 and delivers a nice sonic boom to your side and rear speakers with intensity and realism. Extras include a host of promotional junket material that is rather deep and over the top in its explanation of how and why this film was made. If only, as an audience, we had had more clarification as to why Ben and co. were chasing after an illusive treasure, this might have been one good flick. Extras conclude with the theatrical trailer, audio commentary and deleted scenes. Not for the faint-hearted \\u0096 just the thick-headed.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "data = pd.read_csv(\"https://raw.githubusercontent.com/Ankit152/IMDB-sentiment-analysis/master/IMDB-Dataset.csv\")\n",
        "data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ocwc_bCf7HNv",
        "outputId": "e653a1a2-4712-401b-8bce-8c5766e2cd82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of movies in the data set are : 50000\n"
          ]
        }
      ],
      "source": [
        "print(f\"The number of movies in the data set are : {data.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tesSVPbF9uqV"
      },
      "source": [
        "Let us see a few examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "rONxamRw8lX8",
        "outputId": "8dac74b2-4ec0-46c9-97c2-dc1d08ad0ad0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data[\"review\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "s3xUKNpm8pfI",
        "outputId": "338b88dd-b175-4b72-a819-57dde839dd60"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I bought this game on an impulse buy from walmart. I am glad I did. It was very entertaining listening to Sean Connery and playing the game. I thought the graphics were the best I have ever seen in a movie/game remake. The bonus levels were very hard! The sniper one I think was too hard, it made me so frustrated I didn't play the game for a week and a half. There were too many people shooting at you with nothing to hide behind or life to handle it. <br /><br />The only thing I might change was the upgrade system. I didn't notice any difference from un-upgraded equipment to the upgraded, such as buying an armor upgrade didn't seem to make the armor stronger or more filling on my life meter. I really liked the Q copter. I think the developers did a good job.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data[\"review\"][102]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "m94l4DSr8wFt",
        "outputId": "9eb20bc9-dc6b-4b19-8db8-b40b2d4bab78"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The cover art (which features a man holding a scary pellet gun) would make it seem as if it's a martial arts film. (Hardly.)<br /><br />I find it interesting that the film's real title is Trojan Warrior. (Trojan is a brand of condoms in the US) This movie is loaded with homoeroticism. If you like that stuff, then this film isn't that bad really. However, consider these points:<br /><br />There are numerous close-ups of actors' groins & butts, (One scene even features every actor with an erection bulging in his pants.) the film is also bathed in gaudy colors like lime, peach, and red. From a cinematographer's standpoint, this movie's a drag queen! Several scenes feature characters standing EXTREMELY close to one another, occasionally touching as they converse. Also, the cousin of the hero likes women, and every other guy in the movie is trying to kill him. Is there a message here the filmmakers want to convey? <br /><br />Shall I go into the fight scenes? (Yes, someone's private parts get grabbed in one fight.) The martial arts scenes are brief and unimaginative. No fancy stuff here, just your standard moves you'd see in an old Chuck Norris flick. There's also a car chase scene which may be the first ever LOW-speed chase put on film.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data[\"review\"][49281]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xIaNdB779yn"
      },
      "source": [
        "However, there are a few reviews which are not exactly clean. They have HTML tags inside of them and '\\n' line breakers, which we can see from the examples above.\n",
        "\n",
        "Therefore, if this data is used for any learning tasks and is given as training data, it may not be the most apt representation of real world data and the model would tend to give faulty responses. Data integrity is of core importance for any machine learning/AI task. So let us get started with the data cleaning part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3X84g0f9JQA"
      },
      "source": [
        "# Data Cleaning Techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg4K2BG_9Oq5"
      },
      "source": [
        "## Lower Casing\n",
        "First, it is important that we understand that a computer would process capital and small letters in the same words differently, despite them implying the same meaning. Hence to tackle this, it is always advisible to convert everything into small character based words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tvS4nVF7iLK"
      },
      "outputs": [],
      "source": [
        "data[\"review\"] = data[\"review\"].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "82l0qzYv9ks5",
        "outputId": "d13342b1-6c31-4338-c6bd-1f80802e0463"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. the plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). while some may be disappointed when they realize this is not match point 2: risk addiction, i thought it was proof that woody allen is still fully in control of the style many of us have grown to love.<br /><br />this was the most i\\'d laughed at one of woody\\'s comedies in years (dare i say a decade?). while i\\'ve never been impressed with scarlet johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />this may not be the crown jewel of his career, but it was wittier than \"devil wears prada\" and more interesting than \"superman\" a great comedy to go see with friends.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data[\"review\"][2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMhACGkU99x8"
      },
      "source": [
        "## HTML Tag Removal using REGEX\n",
        "We will now remove the html tags in the reviews based on the python module of **Regular Expression**, a descriptive link for which can be found [here](https://docs.python.org/3/library/re.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPPKWg659oS2"
      },
      "outputs": [],
      "source": [
        "def remove_html_tag(text):\n",
        "  # We will create a pattern of html tags (means any content which is encapsulated between HTML tags), and then replace/substitute it with an single space string across the text\n",
        "  pattern = re.compile('<.*?>')\n",
        "  return pattern.sub(\" \",text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDU002PZAZsr"
      },
      "source": [
        "## URL Removal using REGEX\n",
        "Similarly, let us now create a functionality to remove URL data should it exist in our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jr37kR1x-7Zn"
      },
      "outputs": [],
      "source": [
        "def remove_url(text):\n",
        "  # We will create a pattern of url string (means any content which is a URL), and then replace/substitute it with an single space string across the text\n",
        "  pattern = re.compile('https?://\\S+|www\\.\\S+')\n",
        "  return pattern.sub(\" \",text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeDAmXeKBmzz"
      },
      "source": [
        "## Punctuation Removal\n",
        "Similarly, let us now create a functionality to remove any punctuations,  should it exist in our data of reviews. This we will do with the help of **string** library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttdNOTA-Bv5j"
      },
      "outputs": [],
      "source": [
        "punctuations = string.punctuation\n",
        "\n",
        "def remove_punc(text):\n",
        "  # We will run a loop to replace all punctuations (as defined above) with a single space string in a given text\n",
        "  for char in punctuations:\n",
        "    text = text.replace(char,\" \")\n",
        "  return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfTwX_9oECPO"
      },
      "source": [
        "## Abrevation Subsitution\n",
        "Let us now create a functionality to modify any abrevations in a text to their full meaning,  should it exist in our data of reviews. This we will do with the help of giving a dictionary of potential abrevations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56EKKzi7CnO1"
      },
      "outputs": [],
      "source": [
        "chat_words={\n",
        "    \"AFAIK\":\"As Far As I Know\",\n",
        "    \"AFK\": \"Away From Keyboard\",\n",
        "    \"ASAP\":\"As Soon As Possible\",\n",
        "    \"BTW\":\"By The Way\",\n",
        "    \"B4\":\"Before\",\n",
        "    \"FYI\":\"For your information\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2pxv_jPEchr"
      },
      "outputs": [],
      "source": [
        "def chat_conversion(text):\n",
        "    new_text=[]\n",
        "    for w in text.split():\n",
        "        if w.upper() in chat_words:\n",
        "            new_text.append(chat_words[w.upper()])\n",
        "        else:\n",
        "            new_text.append(w)\n",
        "    return \" \".join(new_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2cRI8DGFYLY"
      },
      "source": [
        "## Spelling Correction using TextBlob\n",
        "Here, we will use the **TextBlob class** from the textblob library, which allows us to correct any spelling errors in out data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4YSmMBMExTl"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob # Importing the class module from textblob\n",
        "\n",
        "def correct_spell(text):\n",
        "  instance = TextBlob(text)\n",
        "  return instance.correct().string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjqsurRQG2H7"
      },
      "source": [
        "Note that this TextBlob instance may not able to give the correct spelling for all words, as it does not entirely understand the context as in depth as some high end models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZJKF3PfHJ9p"
      },
      "source": [
        "## Stop Words\n",
        "Now, there are some words which do not provide any semantic meaning to the sentence. Although they are required for the text to be cohesive and understandable, they do not neccessarily add any value to the meaning of the text, hence it is adivisble to remove them. Let us download the stopwords from the **NLTK** library.\n",
        "Also, we can create our own manual list with specific stopwords to remove them, in case the current ones are insufficient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hftUadrZIIEA",
        "outputId": "36e4bcd8-5e57-4d7b-cf73-2f896bb20dc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'myself', 'we']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Stopwords list for english language based text\n",
        "Stopwords = stopwords.words(\"english\")\n",
        "Stopwords[:5] # Example of a few stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAp8NiVHIanG"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(text):\n",
        "    new_text=[]\n",
        "\n",
        "    for word in text.split():\n",
        "        if word in Stopwords:\n",
        "            new_text.append(\" \")\n",
        "        else:\n",
        "            new_text.append(word.strip())\n",
        "\n",
        "\n",
        "    return \" \".join(new_text).replace(\"   \",\" \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmMnsaa03NoO"
      },
      "source": [
        "## Emoji Handling\n",
        "There may be a few cases where our textual data would be having emoticons in it. A computer or simple machine may not be able to understand it and what emotion does is exactly represent in the text.\n",
        "Hence, we can remove the emojis or replace them with apporpirate representations using the **Emoji** library in python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSyfB3Kz25RT"
      },
      "outputs": [],
      "source": [
        "def remove_emoji(text):\n",
        "  clean_text = emoji.demojize(text)\n",
        "  return clean_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIKuOG0w4_ON"
      },
      "source": [
        "So, the representation of the emoji above will be replaced by it's english name, which can be seen in the example below :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rg-ZT2S54m_z",
        "outputId": "f5a98d44-6467-4141-abf9-23a687f4cfd2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'en': ':smiling_face_with_smiling_eyes:',\n",
              " 'status': 2,\n",
              " 'E': 0.6,\n",
              " 'alias': [':blush:'],\n",
              " 'de': ':lächelndes_gesicht_mit_lachenden_augen:',\n",
              " 'es': ':cara_feliz_con_ojos_sonrientes:',\n",
              " 'fr': ':visage_souriant_avec_yeux_rieurs:',\n",
              " 'ja': ':にこにこ:',\n",
              " 'ko': ':미소_짓는_눈으로_살짝_웃는_얼굴:',\n",
              " 'pt': ':rosto_sorridente_com_olhos_sorridentes:',\n",
              " 'it': ':faccina_con_occhi_sorridenti:',\n",
              " 'fa': ':لبخند_خجالتی:',\n",
              " 'id': ':wajah_tersenyum_dengan_mata_bahagia:',\n",
              " 'zh': ':羞涩微笑:',\n",
              " 'ru': ':довольно_улыбается:',\n",
              " 'tr': ':ağzı_açık_gülme:',\n",
              " 'ar': ':وجه_باسم_بعينين_باسمتين:'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "emoji.EMOJI_DATA['😊']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtPZE04m5s1_"
      },
      "source": [
        "## Final Pipeline\n",
        "With the above methods, we can now build a pipeline which can clean all our data and use it for processing further."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehSqHIs34unW"
      },
      "outputs": [],
      "source": [
        "def cleaning_pipeline(text):\n",
        "  text = remove_html_tag(text)\n",
        "  text = remove_url(text)\n",
        "  text = remove_punc(text)\n",
        "  text = chat_conversion(text)\n",
        "  text = remove_stopwords(text)\n",
        "  text = remove_emoji(text)\n",
        "  return text\n",
        "\n",
        "data[\"review\"] = data[\"review\"].apply(cleaning_pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS-M0Q-Z7chd"
      },
      "source": [
        "Let us now view the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "Yc674rBa6rap",
        "outputId": "a825872d-db23-45ea-cb88-79d5b7aea586"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  one   reviewers mentioned   watching 1 oz epis...  positive\n",
              "1    wonderful little production filming techniqu...  positive\n",
              "2    thought   wonderful way spend time   hot sum...  positive\n",
              "3  basically   family   little boy jake thinks   ...  negative\n",
              "4  petter mattei love   time money   visually stu...  positive\n",
              "5  probably   time favorite movie story selflessn...  positive\n",
              "6    sure would like see resurrection   dated sea...  positive\n",
              "7    show   amazing fresh innovative idea   70   ...  negative\n",
              "8  encouraged   positive comments   film   lookin...  negative\n",
              "9    like original gut wrenching laughter   like ...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d342c995-469d-45ef-b0c9-7da4c35ec117\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>one   reviewers mentioned   watching 1 oz epis...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wonderful little production filming techniqu...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>thought   wonderful way spend time   hot sum...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>basically   family   little boy jake thinks   ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>petter mattei love   time money   visually stu...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>probably   time favorite movie story selflessn...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>sure would like see resurrection   dated sea...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>show   amazing fresh innovative idea   70   ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>encouraged   positive comments   film   lookin...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>like original gut wrenching laughter   like ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d342c995-469d-45ef-b0c9-7da4c35ec117')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d342c995-469d-45ef-b0c9-7da4c35ec117 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d342c995-469d-45ef-b0c9-7da4c35ec117');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9cdc8915-6299-427a-b505-13151dfc91cc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9cdc8915-6299-427a-b505-13151dfc91cc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9cdc8915-6299-427a-b505-13151dfc91cc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49574,\n        \"samples\": [\n          \"  moving intriguing absorbing however story   little choppy hard follow times although two principal actors   great job seeing senn penn acting every fiber   stealing every frame made   memorable movie later movies revealed     one role actor also showed comedic flair sweet lowdown surprisingly talented   light weight used think  \",\n          \"  seems   becoming fashionable rip basic instinct 2   point   significant part   audience including critics found terrible even   released seems even fashionable trash sharon stone who\\u0097like   us\\u0097is fourteen years older and\\u0097unlike   us\\u0097still looks wonderful first comments   movie   vicious   see   opinion sequel   nearly good   original film   bad   comments pretend michael caton jones   paul verhoeven neither henry bean leora barish joe eszterhas basic instinct 2   entertaining average thriller besides addition jerry goldsmith original score keeps little resemblance   predecessor even stone gives character different dimension creating lustful devilish catherine trimell   perfectly well rank among monsters like hannibal lecter   intelligent actress   afraid taking risks   play camp   leisure unfortunately seems   main target   enjoy trashing flick became successful much   main icon like   actors   reached level time arrived   bound   destroyed hollywood audiences rest   cast outstanding giving performances   far better   material deserves david morrissey   much better actor   far interesting michael douglas acting flawless giving dense complex dimension   otherwise one dimensional character since   screen time   axis   movie   keep attention beginning end   recommending basic instinct 2   great movie   expressing disagreement   comments   site   conviction agendas   movie   shaping opinion   spectators\",\n          \"dear reader watch   movie   really movie though creators   impertinence call     warned   content   goes film simply sequence imagines flow continually   trying transmit certain feeling concept could called therefore symbols images accompanied   soundtrack   purpose   create atmosphere well however images director chosen   transmit feelings   american audience     overwhelming number american icons though film intended express idea civilized warfare fails       general chaos also   far long tiresome   strongly felt   lot   scenes     war whichever conception conclude   greatly disappointed   documentary   documentary movie   movie something whose strong point   extraordinary use technology image processing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sliq0Eu77YW"
      },
      "source": [
        "# Tokenization\n",
        "To train on text data, one very important concept is of **tokens**. They can be understood as a basic unit of data which is given as input and received as output. In textual data, a token represents words, subwords or characters. For now, we will perform the conversion of text to tokens via the **nltk** library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jywSkqX7wJQ",
        "outputId": "a95760b9-0a2d-43c0-975d-4312e4244538"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "nltk.download(\"punkt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6nxtU1y_idP"
      },
      "source": [
        "Now say if we have a text with multiple sentences, we can convert it into **Sentence Tokens** which basically convert texts into tokens where each token represents a sentence or a chunk of the overall text. Let us see the example below :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YY1Z1ifO--Xc"
      },
      "outputs": [],
      "source": [
        "my_text = \"\"\"Training and inference are two distinct phases in the lifecycle of a machine learning model.\n",
        "\n",
        "During training, the model learns from the input data and adjusts its parameters to minimize the difference between its predictions and the actual target values. This process involves backpropagation, optimization algorithms, and iterative updates to the model's parameters.\n",
        "\n",
        "Inference is the phase where the trained model is used to make predictions on new, unseen data. During inference, the model takes input data and generates output predictions based on the learned patterns and relationships in the training data. Inference is typically faster and less computationally intensive than training, as the model's parameters are fixed and do not need to be updated.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hn9ftvyQAJ7h",
        "outputId": "bd72cde6-8dcb-48e1-af20-32bd9d0935b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Training and inference are two distinct phases in the lifecycle of a machine learning model.',\n",
              " 'During training, the model learns from the input data and adjusts its parameters to minimize the difference between its predictions and the actual target values.',\n",
              " \"This process involves backpropagation, optimization algorithms, and iterative updates to the model's parameters.\",\n",
              " 'Inference is the phase where the trained model is used to make predictions on new, unseen data.',\n",
              " 'During inference, the model takes input data and generates output predictions based on the learned patterns and relationships in the training data.',\n",
              " \"Inference is typically faster and less computationally intensive than training, as the model's parameters are fixed and do not need to be updated.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "sent_tokenize(my_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38S3ZlozAemE"
      },
      "source": [
        "Now, we can also create **Word Tokens** for the above, as shown below :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAo1j29IAM9N",
        "outputId": "290cabdb-c20b-44f1-e1bb-7b06e0469d24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Training',\n",
              " 'and',\n",
              " 'inference',\n",
              " 'are',\n",
              " 'two',\n",
              " 'distinct',\n",
              " 'phases',\n",
              " 'in',\n",
              " 'the',\n",
              " 'lifecycle',\n",
              " 'of',\n",
              " 'a',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'model',\n",
              " '.',\n",
              " 'During',\n",
              " 'training',\n",
              " ',',\n",
              " 'the',\n",
              " 'model',\n",
              " 'learns',\n",
              " 'from',\n",
              " 'the',\n",
              " 'input',\n",
              " 'data',\n",
              " 'and',\n",
              " 'adjusts',\n",
              " 'its',\n",
              " 'parameters',\n",
              " 'to',\n",
              " 'minimize',\n",
              " 'the',\n",
              " 'difference',\n",
              " 'between',\n",
              " 'its',\n",
              " 'predictions',\n",
              " 'and',\n",
              " 'the',\n",
              " 'actual',\n",
              " 'target',\n",
              " 'values',\n",
              " '.',\n",
              " 'This',\n",
              " 'process',\n",
              " 'involves',\n",
              " 'backpropagation',\n",
              " ',',\n",
              " 'optimization',\n",
              " 'algorithms',\n",
              " ',',\n",
              " 'and',\n",
              " 'iterative',\n",
              " 'updates',\n",
              " 'to',\n",
              " 'the',\n",
              " 'model',\n",
              " \"'s\",\n",
              " 'parameters',\n",
              " '.',\n",
              " 'Inference',\n",
              " 'is',\n",
              " 'the',\n",
              " 'phase',\n",
              " 'where',\n",
              " 'the',\n",
              " 'trained',\n",
              " 'model',\n",
              " 'is',\n",
              " 'used',\n",
              " 'to',\n",
              " 'make',\n",
              " 'predictions',\n",
              " 'on',\n",
              " 'new',\n",
              " ',',\n",
              " 'unseen',\n",
              " 'data',\n",
              " '.',\n",
              " 'During',\n",
              " 'inference',\n",
              " ',',\n",
              " 'the',\n",
              " 'model',\n",
              " 'takes',\n",
              " 'input',\n",
              " 'data',\n",
              " 'and',\n",
              " 'generates',\n",
              " 'output',\n",
              " 'predictions',\n",
              " 'based',\n",
              " 'on',\n",
              " 'the',\n",
              " 'learned',\n",
              " 'patterns',\n",
              " 'and',\n",
              " 'relationships',\n",
              " 'in',\n",
              " 'the',\n",
              " 'training',\n",
              " 'data',\n",
              " '.',\n",
              " 'Inference',\n",
              " 'is',\n",
              " 'typically',\n",
              " 'faster',\n",
              " 'and',\n",
              " 'less',\n",
              " 'computationally',\n",
              " 'intensive',\n",
              " 'than',\n",
              " 'training',\n",
              " ',',\n",
              " 'as',\n",
              " 'the',\n",
              " 'model',\n",
              " \"'s\",\n",
              " 'parameters',\n",
              " 'are',\n",
              " 'fixed',\n",
              " 'and',\n",
              " 'do',\n",
              " 'not',\n",
              " 'need',\n",
              " 'to',\n",
              " 'be',\n",
              " 'updated',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "word_tokenize(my_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwNXaxXRAsyk"
      },
      "source": [
        "Although the word tokens do have have some stopwords and uneccessary words, the function divides the text into a collection of words successfully.\n",
        "\n",
        "Now, using the above we can tokenize any given corpus/document into a collection of sentences. These sentences will be needed for further processes such as **encoding** about which we will learn below.\n",
        "\n",
        "We will be using this technique ahead coupled with one of the following approaches as explained below to pre-process our data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x93X6JluoZ8"
      },
      "source": [
        "# Stemming\n",
        "Stemming is the process of reducing inflected (or sometimes derived) words to their word stem, base or root form— generally a written word form. In all languages, many words originate from the same root word, which implies the same meaning, just in a different contextual use. Basically, it converts the words to their roots by the process of trimming and hence, is a relatively faster process.\n",
        "\n",
        "\n",
        "For example, \"fishing\", \"fished\", \"fisher\" all have the same root word, \"fish\" and all of them are related to the root word only.\n",
        "\n",
        "\n",
        "Stemming can be used in sentiment analysis, spam filtering, text classification, etc i.e. where it is important to understand the sentiment of the words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1QVgFmXRJwv"
      },
      "outputs": [],
      "source": [
        "paragraph = \"\"\"I have three visions for India. In 3000 years of our history, people from all over\n",
        "                the world have come and invaded us, captured our lands, conquered our minds.\n",
        "                From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British, the French, the Dutch, all of them came and looted us, took over what was ours.\n",
        "                Yet we have not done this to any other nation. We have not conquered anyone. ear history abd tried to enforce our way of life on them.\n",
        "                Why? Because we respect the freedom of others. That is why my first vision is that of freedom. I believe that India got its first vision of this in 1857, when we started the War of Independence. It is this freedom that\n",
        "                My second otston for Lndure s developrent: For fLy years e have ben a developting nation.\n",
        "                It is time we see ourselves as a developed nation. We are among the top 5 nations of the world in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\n",
        "                Our achievements are being globally recognised today. Yet we lack the self-confidence to\n",
        "                I nave s thand vision, ndsa nust tand up to Ene wod e, fecause etreve that untes Ehdsa\n",
        "                Strong not onty as a ns tary power but atto as an coronde porer: Both tret go hand-un-hand.\n",
        "                My good fortune was to have worked with three great minds.\n",
        "                Dr. Vikram Sarabhai of the Dept. of space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash,\n",
        "                father of nuclear materi I was lucky to have worked with all three of them closely and consider this the great opportunity\n",
        "                I see four milestones in my career\"\"\"\n",
        "\n",
        "# Tokenizing sentences\n",
        "sentences = nltk.sent_tokenize(paragraph)\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "\n",
        "# Now, the above sentences are tokenized into words. We will now remove the stopwords and then apply stemming.\n",
        "for i in range(sentences.__len__()):\n",
        "    words = nltk.word_tokenize(sentences[i])\n",
        "    words = [stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))] # Basically, this will only keep those words which are not present in the stopwords corpus\n",
        "    sentences[i] = ' '.join(words) # Joining the words to form a sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkyOBTULSrYH",
        "outputId": "e7b7813a-048b-417e-eebe-96ca5f690eec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i three vision india .',\n",
              " 'in 3000 year histori , peopl world come invad us , captur land , conquer mind .',\n",
              " 'from alexand onward , greek , turk , mogul , portugues , british , french , dutch , came loot us , took .',\n",
              " 'yet done nation .',\n",
              " 'we conquer anyon .',\n",
              " 'ear histori abd tri enforc way life .',\n",
              " 'whi ?',\n",
              " 'becaus respect freedom other .',\n",
              " 'that first vision freedom .',\n",
              " 'i believ india got first vision 1857 , start war independ .',\n",
              " 'it freedom my second otston lndure developr : for fli year e ben developt nation .',\n",
              " 'it time see develop nation .',\n",
              " 'we among top 5 nation world term gdp .',\n",
              " 'we 10 percent growth rate area .',\n",
              " 'our poverti level fall .',\n",
              " 'our achiev global recognis today .',\n",
              " 'yet lack self-confid i nave thand vision , ndsa nust tand ene wod e , fecaus etrev unt ehdsa strong onti ns tari power atto corond porer : both tret go hand-un-hand .',\n",
              " 'my good fortun work three great mind .',\n",
              " 'dr. vikram sarabhai dept .',\n",
              " 'space , professor satish dhawan , succeed dr. brahm prakash , father nuclear materi i lucki work three close consid great opportun i see four mileston career']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Dn9VFAKTATt"
      },
      "source": [
        "We can see above the original paragraph is now divided into sentences, where each word is now trimmed to their base word to further smoothen the process of understanding the context of the words.\n",
        "\n",
        "However, here lies a small problem. The problem with stemming is that it may not return the ideal root word, as it only tries to trim it down to it's root word. It does not take referece from any dictionary and only trims it based on the data it gets.\n",
        "\n",
        "For example, we know that the root word for \"better\" is \"good\", as they both imply the same thing. However, the stemming process may convert it into \"bet\" as it only trims it down.\n",
        "\n",
        "It may even produce intermidiate root words which do not neccessarily mean anything, such as \"intellig\" for \"intelligent\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss3XfUv_uqIq"
      },
      "source": [
        "# Lemmatization\n",
        "Lemmatization is the process of grouping together the inflected forms of a word so they can be analysed as a single item, such as the word \"better\" which is the comparative form of \"good\". This basically tries to convert a word into it's meaningful base word which is known as **lemma**.\n",
        "\n",
        "For example, it is able to convert the words \"better\", \"great\", \"greatest\" into \"good\", and hence provides a more accurate representaion of the words to their roots.\n",
        "\n",
        "Lemmatization can be used in chatbots, question-answering systems, etc i.e. where it is important to understand the meaning of the words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHeKRMzNUE-g"
      },
      "outputs": [],
      "source": [
        "paragraph = \"\"\"I have three visions for India. In 3000 years of our history, people from all over\n",
        "                the world have come and invaded us, captured our lands, conquered our minds.\n",
        "                From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British, the French, the Dutch, all of them came and looted us, took over what was ours.\n",
        "                Yet we have not done this to any other nation. We have not conquered anyone. ear history abd tried to enforce our way of life on them.\n",
        "                Why? Because we respect the freedom of others. That is why my first vision is that of freedom. I believe that India got its first vision of this in 1857, when we started the War of Independence. It is this freedom that\n",
        "                My second otston for Lndure s developrent: For fLy years e have ben a developting nation.\n",
        "                It is time we see ourselves as a developed nation. We are among the top 5 nations of the world in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\n",
        "                Our achievements are being globally recognised today. Yet we lack the self-confidence to\n",
        "                I nave s thand vision, ndsa nust tand up to Ene wod e, fecause etreve that untes Ehdsa\n",
        "                Strong not onty as a ns tary power but atto as an coronde porer: Both tret go hand-un-hand.\n",
        "                My good fortune was to have worked with three great minds.\n",
        "                Dr. Vikram Sarabhai of the Dept. of space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash,\n",
        "                father of nuclear materi I was lucky to have worked with all three of them closely and consider this the great opportunity\n",
        "                I see four milestones in my career\"\"\"\n",
        "\n",
        "# Tokenizing sentences\n",
        "sentences = nltk.sent_tokenize(paragraph)\n",
        "lemitizer = WordNetLemmatizer()\n",
        "\n",
        "# Now, the above sentences are tokenized into words. We will now remove the stopwords and then apply lemmatization.\n",
        "for i in range(sentences.__len__()):\n",
        "    words = nltk.word_tokenize(sentences[i])\n",
        "    words = [lemitizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))] # Basically, this will only keep those words which are not present in the stopwords corpus\n",
        "    sentences[i] = ' '.join(words) # Joining the words to form a sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tFhJ73VXgFs",
        "outputId": "1a7b39ad-797b-4985-aa99-e5ec28924c18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I three vision India .',\n",
              " 'In 3000 year history , people world come invaded u , captured land , conquered mind .',\n",
              " 'From Alexander onwards , Greeks , Turks , Moguls , Portuguese , British , French , Dutch , came looted u , took .',\n",
              " 'Yet done nation .',\n",
              " 'We conquered anyone .',\n",
              " 'ear history abd tried enforce way life .',\n",
              " 'Why ?',\n",
              " 'Because respect freedom others .',\n",
              " 'That first vision freedom .',\n",
              " 'I believe India got first vision 1857 , started War Independence .',\n",
              " 'It freedom My second otston Lndure developrent : For fLy year e ben developting nation .',\n",
              " 'It time see developed nation .',\n",
              " 'We among top 5 nation world term GDP .',\n",
              " 'We 10 percent growth rate area .',\n",
              " 'Our poverty level falling .',\n",
              " 'Our achievement globally recognised today .',\n",
              " 'Yet lack self-confidence I nave thand vision , ndsa nust tand Ene wod e , fecause etreve untes Ehdsa Strong onty n tary power atto coronde porer : Both tret go hand-un-hand .',\n",
              " 'My good fortune worked three great mind .',\n",
              " 'Dr. Vikram Sarabhai Dept .',\n",
              " 'space , Professor Satish Dhawan , succeeded Dr. Brahm Prakash , father nuclear materi I lucky worked three closely consider great opportunity I see four milestone career']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Dg-f732XjrN"
      },
      "source": [
        "As we can see above, the sentences are now brought to the accurate representations of their base/root words.\n",
        "\n",
        "The problem with lemmatization is that it is slower than stemming as it tries to find the root word from the dictionary. This may not be possible for all words, and also it has a higher time complexity as compared to stemming."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsbQ3VLKJTVC"
      },
      "source": [
        "# Stemming V/s Lemmatization - Project Approach\n",
        "For our project, let us view the comparitive view of both these approaches :\n",
        "\n",
        "#### **Stemming**\n",
        "\n",
        "**Pros**\n",
        "* Faster and more computationally efficient, especially for large datasets such as ours (50,000 reviews).\n",
        "* Can be effective at capturing synonyms and reducing vocabulary size.\n",
        "\n",
        "\n",
        "**Cons**\n",
        "* May create nonsensical words (e.g., \"better\" becomes \"bet\").\n",
        "* Might not always capture the correct morphological form (e.g., \"running\" becomes \"run\" which loses the present participle meaning)\n",
        "\n",
        "---\n",
        "#### **Lemmatization**\n",
        "\n",
        "**Pros**\n",
        "* More accurate than stemming, as it considers the context and dictionary to identify the correct base form (lemma) of a word.\n",
        "* Preserves the grammatical meaning of words (e.g., \"running\" remains \"running\" and \"better\" becomes \"good\").\n",
        "\n",
        "**Cons**\n",
        "* Slower and computationally more expensive compared to stemming.\n",
        "* Might require additional resources like a comprehensive dictionary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0pr2Y43Ky80"
      },
      "source": [
        "For sentiment analysis, where capturing the emotional tone is crucial, some minor loss of accuracy from stemming might be acceptable if it translates to significant efficiency gains, especially with a large dataset. Apart from thatm the factors we should consider are :\n",
        "\n",
        "* **Dataset size**: With 50,000 reviews, stemming's speed advantage becomes more appealing.\n",
        "* **Task sensitivity**: If subtle nuances in word meaning are critical, lemmatization might be preferable. However, for sentiment analysis, the core emotional meaning is often preserved even with stemming.\n",
        "\n",
        "Hence, we would be choosing stemming to process the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ui3zy3XvK-gu"
      },
      "outputs": [],
      "source": [
        "def stemming_pipeline(review):\n",
        "  words = nltk.word_tokenize(review)\n",
        "  words = [stemmer.stem(word) for word in words if word]\n",
        "  sentence = ' '.join(words)\n",
        "  return sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0qxjaw8K0w7"
      },
      "outputs": [],
      "source": [
        "data[\"review\"] = data[\"review\"].apply(stemming_pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "6jeceK1nPBIN",
        "outputId": "61d8ef28-467c-4d72-a513-869be02e5cb0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  one review mention watch 1 oz episod hook righ...  positive\n",
              "1  wonder littl product film techniqu unassum old...  positive\n",
              "2  thought wonder way spend time hot summer weeke...  positive\n",
              "3  basic famili littl boy jake think zombi closet...  negative\n",
              "4  petter mattei love time money visual stun film...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-088b9a41-d70d-4f07-bf28-3a75e9b95016\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>one review mention watch 1 oz episod hook righ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wonder littl product film techniqu unassum old...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>thought wonder way spend time hot summer weeke...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>basic famili littl boy jake think zombi closet...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>petter mattei love time money visual stun film...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-088b9a41-d70d-4f07-bf28-3a75e9b95016')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-088b9a41-d70d-4f07-bf28-3a75e9b95016 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-088b9a41-d70d-4f07-bf28-3a75e9b95016');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b2706107-732c-46e9-ba10-cbe08f1d075b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b2706107-732c-46e9-ba10-cbe08f1d075b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b2706107-732c-46e9-ba10-cbe08f1d075b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49572,\n        \"samples\": [\n          \"rent movi huge dudikoff fan figur bad boy wrong 15 minut mark begi other let rip dvd fling back rental store refus swore get better wrong movi lack everyth actor deliv line much emot comatos rock plot ridicul offend hollywood assum peopl dumb enough enjoy none charact interact well ice give one worst perform watch footag wrong plane bad guy stand get shot clip empti miss everyth want scream bang head concret movi hit plateau ignor peopl space station use elev travel space suit need graviti space regardless real astronaut may say finish movi hate want finish movi slow suicid could feel cerebr cortex plan aveng tortur put\",\n          \"unfortun movi reli bad pun taglin titl releg 2 00 bin decid tri second consecut bad movi movi night winner hous dead go one want laughabl flick witch jump water set fire mr miner guy took dump wood guy grab new girlfriend right front old one rememb much els last third movi utterli insipid wait agoni end\",\n          \"without doubt beat street best film breakin scene everyth spot cloth puma music importantli danc storylin basic hey what tell stori whole point film show kid moment time matter show teenag gener good matter everyday kid music danc friendship watch dvd recent plesantli surpris well stood test time cloth look date possibl puma massiv comeback music still sound fresh danc still captiv watch film anyon 10 25 year age see part youth cultur\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSd_wxoWkjl9"
      },
      "source": [
        "# Encoding\n",
        "Now, it is important that for the machine to understand textual data, it needs to represent it as a numerical value or vector. For the machine to draw and perform a similarity search, it can only do so on numerical vectors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j77dbU2lTBd"
      },
      "source": [
        "## Frequency Based\n",
        "Here, we will be encoding a single word/token based on it's frequency in the sample size. The methods to do so are :     \n",
        "\n",
        "* One Hot Encoding (OHE)\n",
        "* Bag of Words (BOW)\n",
        "* N-Grams\n",
        "* Term Frequency - Inverse Document Frequency (TF-IDF)\n",
        "\n",
        "Let us now go ahead and explore all these."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07EwZY31mdHA"
      },
      "source": [
        "### One Hot Encoding\n",
        "This is the most simple way of converting a word to a vector. It is a binary vector representation of the words in the document,which is also known as Count Vectorization.\n",
        "\n",
        "This returns the index of the word in the given vocabulary size. The vocabulary size is the total number of unique words in the document. The length of the vector is the vocabulary size and the index of the word in the vocabulary is marked as **1** and the rest of the indices are marked as **0**, which indicates the presence of that particular word in the overal sentence.\n",
        "\n",
        "Let us understand this with an example using the **sklearn** library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twphue4CApje"
      },
      "outputs": [],
      "source": [
        "sent=[  ['the glass of milk'],\n",
        "     ['the glass of juice'],\n",
        "     ['the cup of tea'],\n",
        "    ['I am a good boy'],\n",
        "     ['I am a good developer'],\n",
        "     ['understand the meaning of words'],\n",
        "     ['your videos are good']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uc6Mk-t5ouHu"
      },
      "outputs": [],
      "source": [
        "# Initilaise and flattening the sentences\n",
        "ohe = OneHotEncoder(handle_unknown='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-BG7ECVo57C"
      },
      "outputs": [],
      "source": [
        "# Fitting and transforming the sentences into arrays\n",
        "encoded_sentences = ohe.fit_transform(sent).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJiTa0rSpLY4",
        "outputId": "d5a033c7-a4bb-4f2c-d4ff-2127f3254342"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "encoded_sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vN_HIX0phMi"
      },
      "source": [
        "Above, we have a matrix where each row represents a sentence and each column represents a word in the vocabulary. The value of each cell indicates whether the word is present in the sentence or not.\n",
        "\n",
        "Now, a key disadvantage in using this method is that it creates a huge **sparse matrix** i.e. a representation has a lot of 0s which do not mean anything other than the negation of the presence of a particular word. Due to this, context is not retained as further processing happens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXYSrSXPuIXb"
      },
      "source": [
        "### Bag of Words\n",
        "Bag of words is a method to convert text data into numerical data. It is a way of extracting features from the text for use in machine learning algorithms.\n",
        "\n",
        "It is called bag of words because any information about the order or structure of words in the document is discarded.\n",
        "The model is only concerned with whether known words occur in the document, not where in the document. Let us see an example using the **sklearn** library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoEUh-sDtG0b",
        "outputId": "869cf2ca-6f9a-496b-df0f-248b7fcc61de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 4, 0, 0, 0, 0],\n",
              "       [1, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "sent=['the glass of the milk',\n",
        "     'the glass of the glass juice',\n",
        "     'the cup of the tea the one on the table',\n",
        "    'I am a good good boy',\n",
        "     'I am a good developer',\n",
        "     'understand the meaning of words',\n",
        "     'your videos are good',]\n",
        "\n",
        "cv = CountVectorizer()\n",
        "X = cv.fit_transform(sent).toarray()\n",
        "\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFvhcdpSxGtP"
      },
      "source": [
        "In the above, each row represents a sentence while each column implies a unique word.\n",
        "\n",
        "This **BOW** method stores the number of times a unique word has occured in a sentence. It is better than the one hot encoding method as it is easier to interpret.\n",
        "\n",
        "However, it also has it's disadvantages. In the case of a large vocabulary, the eventuality is that we will obtain a sparse matrix for most textual data and also, this method will not be able to handle any out of vocabulary words.\n",
        "\n",
        "A major issue here is that it does not capture the semantic meaning of words or the text, it only stores their frequency. Now, since it is only concerned with the frequency of words, it does not take into account the meaning of the words, which is important for any language based task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_AmxCLO1hsX"
      },
      "source": [
        "### N Grams\n",
        "Now, n-grams is a method to convert text data into numerical data and is similar to the method shown above, with only one key difference in it's processing.\n",
        "\n",
        "Instead of now choosing one word at a time to create a vocabulary, here we choose **n** words to create unique pairs of n words (occuring sequentially) combined to form the words/phrases in vocabulary. A few types can be :     \n",
        "\n",
        "* Unigram [Bag of Words] (n=1)\n",
        "* Bigram (n=2)\n",
        "* Trigram (n=3)\n",
        "\n",
        "\n",
        "Let us see an example of a **bigram** using the **sklearn** library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cHU5ovPx9xD",
        "outputId": "c7187b7c-2f2a-4fec-829c-dcb5060ae63a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "        1, 1, 1, 1, 1, 1, 1, 4, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "sent=['the glass of the milk',\n",
        "     'the glass of the glass juice',\n",
        "     'the cup of the tea the one on the table',\n",
        "    'I am a good good boy',\n",
        "     'I am a good developer',\n",
        "     'understand the meaning of words',\n",
        "     'your videos are good',]\n",
        "\n",
        "cv2 = CountVectorizer(ngram_range = (1,2)) # We set the n-gram range to make it process the words in n given pairs. Here, default is (1,1) which implies a unigram\n",
        "X2 = cv2.fit_transform(sent).toarray()\n",
        "\n",
        "X2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHBEOBGE4H0V"
      },
      "source": [
        "Now, although this can capture a bit context as it does create windown to store unique phrases, this can work for simple tasks or as a baseline approach but it may faulter on short and long term dependencies.\n",
        "\n",
        "\n",
        "Hence, we would need another method which tries to further understand the context and meaning of the text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kz_Z-dd1KQr4"
      },
      "source": [
        "### Term Frequency - Inverse Document Frequency (TF-IDF)\n",
        "It is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.\n",
        "It is often used as a weighting factor in information retrieval and text mining.\n",
        "\n",
        "The importance increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus. With this, a word with a higher frequency in a document is implied to have a higher value and is reflected accordingly.\n",
        "\n",
        "TF-IDF is calculated by multiplying two values:\n",
        "\n",
        "* **Term Frequency (TF)**: This measures how often a word appears in a document.\n",
        "\n",
        "* **Inverse Document Frequency (IDF)**: This measures how important a word is to the document collection as a whole.\n",
        "\n",
        "It's formula is :\n",
        "\n",
        "$$ TF * IDF$$\n",
        "\n",
        "\n",
        "IDF Formula:\n",
        "\n",
        " $$IDF = log(\\frac{N + 1}{df + 1})$$\n",
        "\n",
        "\n",
        "Here,\n",
        "* N is the total number of documents in the collection.\n",
        "* df is the number of documents that contain the word.\n",
        "\n",
        "\n",
        "Let us see an example of a **TD-IDF** using the **sklearn** library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPVFGL683RgJ",
        "outputId": "96ac2f9f-972e-4234-dc6b-27e58ce91377"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.43831983, 0.        , 0.        , 0.        , 0.52804154,\n",
              "        0.32528383, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.65056767, 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.69821897, 0.        , 0.42057032, 0.        , 0.        ,\n",
              "        0.25907948, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.51815896, 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.29551211, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.1820412 , 0.29551211, 0.29551211, 0.29551211, 0.29551211,\n",
              "        0.72816479, 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.43137947, 0.        , 0.51968052, 0.        , 0.        ,\n",
              "        0.        , 0.73745773, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.56060334, 0.        , 0.        , 0.        , 0.67535583,\n",
              "        0.        , 0.47918515, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.51578197, 0.        ,\n",
              "        0.3177317 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.3177317 , 0.51578197, 0.        , 0.51578197, 0.        ],\n",
              "       [0.        , 0.53426056, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.37907384, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.53426056, 0.        , 0.53426056]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "sent=['the glass of the milk',\n",
        "     'the glass of the glass juice',\n",
        "     'the cup of the tea the one on the table',\n",
        "    'I am a good good boy',\n",
        "     'I am a good developer',\n",
        "     'understand the meaning of words',\n",
        "     'your videos are good',]\n",
        "\n",
        "tfid = TfidfVectorizer()\n",
        "X_TFIDF = tfid.fit_transform(sent).toarray()\n",
        "X_TFIDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StkbdoX7QI8r"
      },
      "source": [
        "As we can see above, the words are now being captured along with their importance. However, this still does not capture context and the relationship between words as it should ideally."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBQpSUSbPvf_"
      },
      "source": [
        "# Encoding - Project Approach\n",
        "In this project, our core focus is sentiment analysis. In sentiment analysis, transforming textual reviews into numerical features suitable for machine learning models is crucial. While several techniques exist, TF-IDF (Term Frequency-Inverse Document Frequency) offers distinct advantages when dealing with sentiment analysis data, especially compared to Bag-of-Words (BOW), N-grams, and One-Hot Encoding, such as :\n",
        "\n",
        "**Focus on Important Words**\n",
        "* TF-IDF goes beyond simple word frequency like BOW. It considers both how often a word appears within a review (Term Frequency) and how rare it is across all reviews (Inverse Document Frequency).\n",
        "* This prioritizes words that are significant for a specific review but not overly common, leading to a more nuanced representation of sentiment.\n",
        "\n",
        "**Handling Rare Words**\n",
        "* Unlike BOW and N-grams, which can struggle with rare words, TF-IDF assigns them weight based on their overall rarity.\n",
        "* This helps identify sentiment indicators that might be infrequent but hold strong emotional significance.\n",
        "\n",
        "**Sparse Feature Representation**\n",
        "* Compared to One-Hot Encoding, which creates a high-dimensional sparse matrix, TF-IDF results in a more compact representation.\n",
        "* This reduces computational complexity and improves model training efficiency, especially for large datasets.\n",
        "\n",
        "**Focus on Sentiment**:\n",
        "* By emphasizing words that convey sentiment within a specific review, TF-IDF captures the emotional tone more effectively.\n",
        "* This allows your machine learning model to learn the subtle differences in language that express positive, negative, or neutral sentiment.\n",
        "\n",
        "Hence, we will be choosing **TF-IDF** for this project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxfB9LALRvm7"
      },
      "outputs": [],
      "source": [
        "tfid = TfidfVectorizer()\n",
        "features = tfid.fit_transform(data['review'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gmp80erwTUom"
      },
      "source": [
        "# Train Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFz0Pfk9TQ5F"
      },
      "source": [
        "Let us now create the sentiment column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wm91LTgTikP",
        "outputId": "fab99bee-4abe-489f-9caf-b1f6ddb27366"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['positive', 'negative'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "data[\"sentiment\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lh24gKaARvkl"
      },
      "outputs": [],
      "source": [
        "def sentiment_class(sentiment):\n",
        "  if(sentiment==\"positive\"):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "\n",
        "sentiment = data[\"sentiment\"].apply(sentiment_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYNQcUUQRveq"
      },
      "outputs": [],
      "source": [
        "# Performing the split\n",
        "x_train, x_test, y_train, y_test = train_test_split(features,sentiment, test_size = 0.2, random_state = 1, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3F1NLMEIRvcC",
        "outputId": "510a12b5-1c51-402d-af45-0c8e74b24be0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of training samples are : 40000\n",
            "The number of test samples are : 10000 \n"
          ]
        }
      ],
      "source": [
        "print(f\"The number of training samples are : {x_train.shape[0]}\")\n",
        "print(f\"The number of test samples are : {x_test.shape[0]} \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvlQjlP-Y2Fr"
      },
      "source": [
        "# Metric Selection\n",
        "Before selecting a metric, let us see how our data set is distributed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ps_CUFrY8Y5",
        "outputId": "b4b7225b-5dd3-4e57-dd42-8ba0cd0168a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment\n",
              "positive    25000\n",
              "negative    25000\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "data['sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZAHejUMY-nk"
      },
      "source": [
        "As we can see, our data is a perfectly balanced data set. Since our dataset is perfectly balanced (equal number of reviews in each sentiment category - positive, negative, neutral), **F1-score** is an excellent choice for evaluating the sentiment analysis model's performance. We can say so as :\n",
        "\n",
        "\n",
        "* **Balances Precision and Recall**:\n",
        "  * F1-score is the harmonic mean of precision and recall. This means it takes both metrics into account and provides a single score that reflects the model's ability to identify true positives while minimizing false positives and false negatives.\n",
        "\n",
        "* **Focus on Overall Performance**:\n",
        "  * In a balanced dataset, F1-score directly reflects the model's accuracy in correctly classifying reviews across all sentiment categories. It avoids the potential pitfalls of focusing solely on precision or recall.\n",
        "\n",
        "* **Clear Interpretation**:\n",
        "  * A high F1-score indicates that the model performs well on both identifying relevant reviews (high recall) and avoiding misclassifications (high precision)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrhgNLe2U4iE"
      },
      "source": [
        "# Model Selection\n",
        "Here, we will perform with model selection on multiple classification models and will perform comparitive analysis to select our final model. Now, instead of apporaching all possible classification models, we will go with the following hybrid approach :     \n",
        "\n",
        "\n",
        "* **Start with a few well-suited models**\n",
        "  * Here, we will choose 3-5 models commonly used for sentiment analysis with justifications for each\n",
        "* **Training and evaluate these models**\n",
        "  * This gives us a baseline performance and insights into your data's characteristics.\n",
        "* **Additional models**\n",
        "  * If the initial models perform poorly, we might want to explore a few more with justifications based on some findings.\n",
        "\n",
        "So to begin with, let us start with a few models :\n",
        "\n",
        "1. **Logistic Regression**: Interpretable and works well with TF-IDF features.\n",
        "\n",
        "2. **Support Vector Machine (SVC)**: Powerful for handling high-dimensional data and non-linear relationships.\n",
        "\n",
        "3. **Naive Bayes (MultinomialNB)**: Simple, efficient, and often performs well for text classification tasks.\n",
        "\n",
        "4. **Random Forest**: Robust to overfitting and can handle complex data.\n",
        "\n",
        "5. **XGBoost**: Powerful ensemble method for achieving high accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4C27FqU7VLGG"
      },
      "outputs": [],
      "source": [
        "#Creating dictionary to store model scores\n",
        "scores_train = dict()\n",
        "scores_test = dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFiuuBf3bYbR"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9k2KO_eKVLD8"
      },
      "outputs": [],
      "source": [
        "lr = LogisticRegression()\n",
        "lr.fit(x_train,y_train)\n",
        "y_pred_lr = lr.predict(x_test)\n",
        "y_pred_lr_train = lr.predict(x_train)\n",
        "\n",
        "f1_lr_train = f1_score(y_train,y_pred_lr_train)\n",
        "f1_lr_test = f1_score(y_test,y_pred_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-gEpR0RVLB2",
        "outputId": "166ef581-32f2-46e3-a295-c2974e0049ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The score on training data is : 0.8790688498717697\n",
            "The score on test data is : 0.8666799125769918\n"
          ]
        }
      ],
      "source": [
        "scores_train[\"Logistic Regression\"] = f1_lr_train\n",
        "scores_test[\"Logistic Regression\"] = f1_lr_test\n",
        "\n",
        "print(f\"The score on training data is : {f1_lr_train}\")\n",
        "print(f\"The score on test data is : {f1_lr_test}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlQuiLgPevmp"
      },
      "source": [
        "## Support Vector Classifier (SVC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCzGiAYQezq-"
      },
      "outputs": [],
      "source": [
        "svc = SVC()\n",
        "svc.fit(x_train,y_train)\n",
        "y_pred_svc = svc.predict(x_test)\n",
        "y_pred_svc_train = svc.predict(x_train)\n",
        "\n",
        "f1_svc_train = f1_score(y_train,y_pred_svc_train)\n",
        "f1_svc_test = f1_score(y_test,y_pred_svc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GS5p3beXeznB",
        "outputId": "63bc9723-1842-438b-eb19-6ddf857671dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The score on training data is : 0.9624736123183908\n",
            "The score on test data is : 0.870557871749057\n"
          ]
        }
      ],
      "source": [
        "scores_train[\"Support Vector Classifier\"] = f1_svc_train\n",
        "scores_test[\"Support Vector Classifier\"] = f1_svc_test\n",
        "\n",
        "print(f\"The score on training data is : {f1_svc_train}\")\n",
        "print(f\"The score on test data is : {f1_svc_test}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJKqmAacijrL"
      },
      "source": [
        "## Naive Bayes (Multinomial NB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oX0bt7tFiqKV"
      },
      "outputs": [],
      "source": [
        "mnb = MultinomialNB()\n",
        "mnb.fit(x_train,y_train)\n",
        "y_pred_mnb = mnb.predict(x_test)\n",
        "y_pred_mnb_train = mnb.predict(x_train)\n",
        "\n",
        "f1_mnb_train = f1_score(y_train,y_pred_mnb_train)\n",
        "f1_mnb_test = f1_score(y_test,y_pred_mnb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtX34zsOip4O",
        "outputId": "10a42533-c624-45c1-b1b4-c71360dca1dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The score on training data is : 0.8421621090873388\n",
            "The score on test data is : 0.8361581920903954\n"
          ]
        }
      ],
      "source": [
        "scores_train[\"Multinomial NB\"] = f1_mnb_train\n",
        "scores_test[\"Multinomial NB\"] = f1_mnb_test\n",
        "\n",
        "print(f\"The score on training data is : {f1_mnb_train}\")\n",
        "print(f\"The score on test data is : {f1_mnb_test}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pIndBALiqqM"
      },
      "source": [
        "## Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFwFtCBsivxM"
      },
      "outputs": [],
      "source": [
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(x_train,y_train)\n",
        "y_pred_rfc = rfc.predict(x_test)\n",
        "y_pred_rfc_train = rfc.predict(x_train)\n",
        "\n",
        "f1_rfc_train = f1_score(y_train,y_pred_rfc_train)\n",
        "f1_rfc_test = f1_score(y_test,y_pred_rfc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5XP2rNLivuY",
        "outputId": "8e814053-c8ab-41af-b773-3a815822c10e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The score on training data is : 1.0\n",
            "The score on test data is : 0.8379518072289157\n"
          ]
        }
      ],
      "source": [
        "scores_train[\"Random Forest Classifier\"] = f1_rfc_train\n",
        "scores_test[\"Random Forest Classifier\"] = f1_rfc_test\n",
        "\n",
        "print(f\"The score on training data is : {f1_rfc_train}\")\n",
        "print(f\"The score on test data is : {f1_rfc_test}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVB2kOcdiwP7"
      },
      "source": [
        "## XG-Boost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPGzgDGcizns"
      },
      "outputs": [],
      "source": [
        "xgbc = XGBClassifier()\n",
        "xgbc.fit(x_train,y_train)\n",
        "y_pred_xgbc = xgbc.predict(x_test)\n",
        "y_pred_xgbc_train = xgbc.predict(x_train)\n",
        "\n",
        "f1_xgbc_train = f1_score(y_train,y_pred_xgbc_train)\n",
        "f1_xgbc_test = f1_score(y_test,y_pred_xgbc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCUl-3CqizbN",
        "outputId": "7fba69dc-2d01-4f7f-ba2e-b2b3f2e802f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The score on training data is : 0.9353918772740684\n",
            "The score on test data is : 0.8525849335302806\n"
          ]
        }
      ],
      "source": [
        "scores_train[\"XG-Boost Classifier\"] = f1_xgbc_train\n",
        "scores_test[\"XG-Boost Classifier\"] = f1_xgbc_test\n",
        "\n",
        "print(f\"The score on training data is : {f1_xgbc_train}\")\n",
        "print(f\"The score on test data is : {f1_xgbc_test}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us see how well the models perform visually."
      ],
      "metadata": {
        "id": "q_UrN_bkl-cS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = ['LR','SVC','MNB','RFC','XGBC']\n",
        "x = range(len(models))\n",
        "bar_width = 0.35\n",
        "\n",
        "plt.bar(x, scores_train.values(), bar_width, label='Training Score', color='b')\n",
        "\n",
        "plt.bar([p + bar_width for p in x], scores_test.values(), bar_width, label='Test Score', color='orange')\n",
        "\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('F1-Score')\n",
        "plt.title('Comparison of Training and Test Scores')\n",
        "\n",
        "plt.xticks([p + bar_width / 2 for p in x], models, rotation=45)\n",
        "\n",
        "\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "UeFpk-9pmvAZ",
        "outputId": "d331801b-67e4-45cf-daeb-7c2461d60b9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MndNqe-s5RDO"
      },
      "source": [
        "# Final Model Selection and Evaluation\n",
        "From the above information, let us use the **Logistic Regression** to train on the entire data set, as it works well on both training and test data.\n",
        "\n",
        "Also, we will use this model as it is a basic model and would demonstrate our point well."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(\n",
        "    C=1.0, class_weight=None, dual=False,\n",
        "    fit_intercept=True, intercept_scaling=1,\n",
        "    l1_ratio=None, max_iter=100,\n",
        "    multi_class='auto', n_jobs=None,\n",
        "    penalty='l2', random_state=None,\n",
        "    solver='lbfgs', tol=0.0001, verbose=0,\n",
        "    warm_start=False\n",
        "    )\n",
        "model.fit(features,sentiment)"
      ],
      "metadata": {
        "id": "o8s4NmxwdwlZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "7272b10c-e515-443d-c799-391220fda831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_model = model.predict(x_test)\n",
        "y_pred_model_train = model.predict(x_train)\n",
        "\n",
        "f1_model_train = f1_score(y_train,y_pred_model_train)\n",
        "f1_model_test = f1_score(y_test,y_pred_model)"
      ],
      "metadata": {
        "id": "03Swy3w76mNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The final score on training data is : {f1_model_train}\")\n",
        "print(f\"The final score on test data is : {f1_model_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaLX3C266zCb",
        "outputId": "45c9c607-b465-4e33-9c7e-975016c4b3da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The final score on training data is : 0.9267411950929957\n",
            "The final score on test data is : 0.9268583938700368\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "In this exploration of sentiment analysis, we've witnessed the transformative power of data pre-processing. By prioritizing text cleaning, stemming, and TF-IDF, we constructed a foundation that empowered even a simple model like Logistic Regression to achieve an impressive F1-score of 92% approximately.\n",
        "\n",
        "This accomplishment highlights two key takeaways:\n",
        "\n",
        "* **Pre-processing as the Cornerstone**\n",
        "  * Text cleaning removes noise and inconsistencies, stemming captures word essence, and TF-IDF prioritizes relevant terms.\n",
        "  * These techniques significantly enhance a model's ability to grasp the sentiment within the text data.\n",
        "\n",
        "* **Simple Model, Strong Impact**\n",
        "  * The high score achieved with LR underscores the critical role of data preparation. If a basic model can perform so well, it speaks volumes about the effectiveness of our pre-processing pipeline.\n",
        "\n",
        "The 92% F1-score serves as a springboard for further exploration. We can delve into more complex models like LSTMs or ensemble methods like stacking to potentially push the boundaries of performance. Additionally, working with larger datasets could unlock even greater accuracy. We can see another technique in the next section.\n",
        "\n",
        "Sentiment analysis thrives on a strong foundation of data pre-processing. By investing time in cleaning and structuring your text data, we empower our models to extract valuable insights and unlock the power of sentiment analysis."
      ],
      "metadata": {
        "id": "xJu05BSAq-SG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnwS35FNGDbp"
      },
      "source": [
        "# A Shift Towards Embeddings and advanced models\n",
        "\n",
        "While techniques like stemming, lemmatization, bag-of-words, n-grams, and TF-IDF have been instrumental in text classification for many years, particularly in domains like spam filtering and sentiment analysis, they have a significant limitation: they fail to capture the semantic meaning of text. These methods treat words in isolation, neglecting the relationships and context that are crucial for accurate classification.\n",
        "\n",
        "Imagine a sentence like \"The bank is on the river.\" By simply analyzing individual words, a traditional encoding method might struggle to differentiate between a financial institution and the edge of a body of water. This is where embedding-based methods come into play. These techniques go beyond word frequency and consider the semantic relationships between words, creating a richer representation of text that can be understood by machine learning models.\n",
        "\n",
        "The shift towards embedding-based methods for text classification represents a significant advancement in the field. By capturing the nuances of language, these techniques enable models to achieve higher accuracy and tackle more complex classification tasks. As natural language processing continues to evolve, embedding-based methods will likely play an even greater role in unlocking the true potential of text data."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}